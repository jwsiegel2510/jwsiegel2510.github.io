<!DOCTYPE html>
<html>
<head>

    <title>Jonathan W. Siegel</title>

        <meta name="author" content="Jonathan W. Siegel" />
        <meta name="description" content="My Academic Website" />

        <link rel="stylesheet" href="stylesheet.css" type="text/css" />

</head>
<body>


        <div id="page">
                <div id="logo">
                        <p id="logoLink">
                        <h1>Jonathan W. Siegel</h1>
                        <h3>    Texas A&M Mathematics Department <br>
                                College Station, TX 77840<h3>
                        </p>

                </div>

                <div id="nav">
                        <ul>
                                <li><a href="index.html">Home</a></li>
                                <li><a href="research.html">Research</a></li>
                                <li><a href="teaching.html">Teaching</a></li>
                                <li><a href="misc.html">Miscellaneous</a></li>
                        </ul>
                </div>
                <div id="content">
		<h1><b>Publications </b></h1>
<p> A full list of my publications can also be found on my <a href="https://scholar.google.com/citations?user=oI42qIIAAAAJ"><b>Google Scholar Profile</b></a>.</p>
                        <h2><b> Journal Articles </b></h2>
                        <p> <a href="https://academic.oup.com/imajna/advance-article-abstract/doi/10.1093/imanum/draf008/8093586?redirectedFrom=fulltext&login=false"> <b>Convergence and Error Control of Consistent PINNs for Elliptic PDEs </b> </a> <br> <i> IMA Journal of Numerical Analysis (2025) </i> (with Andrea Bonito, Ronald DeVore, and Guergana Petrova) </p>
                        <p> <a href="https://www.sciencedirect.com/science/article/pii/S1063520324000903"> <b>Weighted Variation Spaces and Approximation by Shallow ReLU Networks </b> </a> <br> <i> Applied and Computational Harmonic Analysis (2025) </i> (with Ronald DeVore, Robert Nowak, and Rahul Parhi) </p>
                        <p> <a href="https://www.sciencedirect.com/science/article/abs/pii/S092702562400716X"> <b>Efficient Structure-Informed Featurization and Property Prediction of Ordered, Dilute, and Random Atomic Structures </b> </a> <br> <i> Computational Materials Science (2025) </i> (with Adam Krajewski and Zi-Kui Liu) </p>
                        <p> <a href="https://www.sciencedirect.com/science/article/pii/S0885064X2400061X"> <b> Sharp Lower Bounds on the Manifold Widths of Sobolev and Besov Spaces </b> </a> <br> <i>Journal of Complexity (2024) </i> </p>
                        <p> <a href="https://www.worldscientific.com/doi/abs/10.1142/S0218202524500143"> <b> Entropy-based Convergence Rates of Greedy Algorithms </b> </a> <br> <i>Mathematical Models and Methods in Applied Sciences (2024) </i> (with Yuwen Li) </p>
                        <p> <a href="https://jmlr.org/papers/volume24/23-0025/23-0025.pdf"> <b> Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and Besov Spaces </b> </a> <br> <i>Journal of Machine Learning Research (2023) </i> </p>
                        <p> <a href="https://www.sciencedirect.com/science/article/pii/S0021999123001791"> <b> Greedy Training Algorithms for Neural Networks and Applications to PDEs </b> </a> <br> <i>Journal of Computational Physics (2023) </i> (with Qingguo Hong, Wenrui Hao, Xianlin Jin and Jinchao Xu) </p>
                        <p> <a href="https://link.springer.com/article/10.1007/s00365-023-09626-4"> <b> Characterization of the Variation Spaces Corresponding to Shallow Neural Networks </b> </a> <br> <i> Constructive Approximation (2023) </i>(with Jinchao Xu) </p>
                        <p> <a href="https://www.global-sci.org/intro/article_detail/jcm/21637.html"><b>
                        Extended Regularized Dual Averaging Methods for Stochastic Optimization </b></a> <br> <i> Journal of Computational Mathematics (2023) </i> (with Jinchao Xu) </p>   
                        <p> <a href="https://link.springer.com/article/10.1007/s10208-022-09595-3"> <b> Sharp Bounds on the Approximation Rates, Metric Entropy, and n-Widths of Shallow Neural Networks </b> </a> <br> <i> Foundations of Computational Mathematics (2022) </i> (with Jinchao Xu) </p>
                        <p> <a href="https://link.springer.com/article/10.1007/s40687-022-00346-y"> <b> Uniform Approximation Rates and Metric Entropy of Shallow Neural Networks </b> </a> <br> <i> Research in the Mathematical Sciences (2022) </i> (with Limin Ma and Jinchao Xu) </p>
                        <p> <a href="https://arxiv.org/abs/2008.13654"> <b> Extensible Structure-Informed Prediction of Formation Energy with Improved Accuracy and Usability employing Neural Networks</b> </a> <br> <i> Computational Materials Science (2022) </i> (with Adam Krajewski, Zi-Kui Liu, and Jinchao Xu) </p>
                        <p> <a href="https://arxiv.org/abs/2106.15000"> <b> Optimal Convergence Rates for the Orthogonal Greedy Algorithm </b> </a> <br> <i> IEEE Transactions on Information Theory (2022) </i> (with Jinchao Xu) </p>
                        <p> <a href="https://arxiv.org/abs/2012.07205"> <b> High-Order Approximation Rates for Shallow Neural Networks with Cosine and ReLUk Activation Functions </b> </a><br> <i> <a href="https://www.journals.elsevier.com/applied-and-computational-harmonic-analysis">Applied and Computational Harmonic Analysis</a> (2022)</i> (with Jinchao Xu) </p>
                        <p> <a href="https://arxiv.org/abs/1903.05204"><b>
                        Accelerated Optimization with Orthogonality Constraints </b></a> <br> <i> <a href="http://www.global-sci.org/jcm/">Journal of Computational Mathematics</a> (2020) </i></p>
                        <p> <a href="https://arxiv.org/abs/1904.02311"><b>
                        Approximation Rates for Neural Networks with General Activation Functions </b></a> <br> <i> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608020301891"> Neural Networks (2020) </a></i> (with Jinchao Xu)</p>
                        <p> <a href="https://epubs.siam.org/doi/abs/10.1137/18M1220595"><b>
                        Accuracy, Efficiency and Optimization of Signal Fragmentation </b></a> <br> <i> Multiscale Simulation and Modelling (2020) </i> (with Russel Caflisch and Edward Chou)</p>
                        <p> <a href="https://www.intlpress.com/site/pub/pages/journals/items/cms/content/vols/0015/0006/a013/index.php?mode=ns"><b>
                        Compact Support Of L1 Penalized Variational Problems </b></a> <br> <i> Communications in Mathematical Sciences (2017) </i> (with Omer Tekin)</p>

                        <h2> <b>Conference Papers </b></h2>
                        <p> <a href="https://arxiv.org/pdf/2402.16077v2"> <b> Equivariant Frames and the Impossibility of Continuous Canonicalization </b> </a> <br> <i> International Conference on Machine Learning (2024) </i> (with Nadav Dym and Hannah Lawrence) </p>
                        <p> <a href="https://arxiv.org/abs/2302.05515"> <b> Achieving Acceleration Despite Very Noisy Gradients </b> </a> <br> <i> Conference on Neural Information Processing Systems (2024) </i> (with Kanan Gupta and Stephan Wojtowsytsch) </p>
                        <p> <a href="https://arxiv.org/abs/2410.01803"> <b>On the Expressiveness and Spectral Bias of KANs </b> </a> <br> <i> Internation Conference on Learning Representations (2025) </i> (with Yixuan Wang, Ziming Liu, and Thomas Y. Hou) </p>
                        <h2> <b>Preprints and Works in Progress </b></h2>
                        <p> <a href="https://arxiv.org/abs/2502.17671"> <b>Optimal Recovery Meets Minimax Estimation </b> </a> <i> (with Ronald DeVore, Robert Nowak, Rahul Parhi, and Guergana Petrova) </i> </p>
                        <p> <a href="https://arxiv.org/abs/2408.10996"> <b>Approximation Rates for Shallow ReLUk Neural Networks on Sobolev Spaces via the Radon Transform </b> </a> <i> (with Tong Mao and Jinchao Xu) </i> </p>
                        <p> <a href="https://arxiv.org/abs/2307.07679"> <b> Sharp Convergence Rates for Matching Pursuit </b> </a> <i> (with Jason Klusowski) </i> </p>
                        <p> <a href="https://arxiv.org/abs/2307.15285"> <b> Optimal Approximation of Zonoids and Uniform Approximation by Shallow Neural Networks </b> </a> <i> </i> </p>
                        <p> <a href="https://arxiv.org/abs/2302.00834"> <b> Sharp Lower Bounds on Interpolation by Deep ReLU Neural Networks at Irregularly Spaced Data </b> </a> </p>
                        <p> <a href="https://arxiv.org/abs/2208.04924"> <b> On the Activation Function Dependence of the Spectral Bias of Neural Networks </b> </a> <i> (with Qinyang Tan, Qingguo Hong, and Jinchao Xu) </i> </p>
                        <p> <a href="https://arxiv.org/abs/2008.09661"><b> Training Sparse Neural Networks using Compressed Sensing </b></a> <i> (with Jianhong Chen and Jinchao Xu) </i> </p>
                        <p> <a href="https://arxiv.org/abs/1903.05671"><b> Accelerated First-Order Methods: Differential Equations and Lyapunov Functions </b></a> </p>
        </div>
</body>
</html>

